{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c34c15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils import resample\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "#import tensorflow-addons as tfa\n",
    "\n",
    "# ==== Configuration ====\n",
    "DATA_DIRS = [\"Audio_Song_Actors_01-24\", \"Audio_Speech_Actors_01-24\"]\n",
    "SAMPLE_RATE = 22050\n",
    "N_MFCC = 40\n",
    "MAX_LEN = 216  # longer padding for full clips\n",
    "\n",
    "# ==== Feature Extraction ====\n",
    "def extract_features(file_path):\n",
    "    y, sr = librosa.load(file_path, sr=SAMPLE_RATE)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=N_MFCC).T\n",
    "    chroma = librosa.feature.chroma_stft(y=y, sr=sr).T\n",
    "    zcr = librosa.feature.zero_crossing_rate(y).T\n",
    "    rms_feature = librosa.feature.rms(y=y).T\n",
    "\n",
    "    def pad(x):\n",
    "        return x[:MAX_LEN] if x.shape[0] >= MAX_LEN else np.pad(x, ((0, MAX_LEN - x.shape[0]), (0, 0)), mode='constant')\n",
    "\n",
    "    mfcc = pad(mfcc)\n",
    "    chroma = pad(chroma)\n",
    "    zcr = pad(zcr)\n",
    "    rms_feature = pad(rms_feature)\n",
    "\n",
    "    return np.concatenate([mfcc, chroma, zcr, rms_feature], axis=1)\n",
    "\n",
    "\n",
    "X, y = [], []\n",
    "\n",
    "# ==== Dataset Preparation ====\n",
    "for data_dir in DATA_DIRS:\n",
    "    for emotion_label in os.listdir(data_dir):\n",
    "        subfolder_path = os.path.join(data_dir, emotion_label)\n",
    "        if not os.path.isdir(subfolder_path):\n",
    "            continue\n",
    "        for file in os.listdir(subfolder_path):\n",
    "            if file.endswith(\".wav\"):\n",
    "                try:\n",
    "                    path = os.path.join(subfolder_path, file)\n",
    "                    features = extract_features(path)\n",
    "                    X.append(features)\n",
    "                    y.append(emotion_label)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {file}: {e}\")\n",
    "\n",
    "X = np.array(X)\n",
    "\n",
    "# ==== Balance Dataset ====\n",
    "df = pd.DataFrame({'x': X.tolist(), 'y': y})\n",
    "min_count = df['y'].value_counts().min()\n",
    "balanced_df = df.groupby('y').apply(lambda g: g.sample(min_count, random_state=42)).reset_index(drop=True)\n",
    "\n",
    "X_balanced = np.stack(balanced_df['x'].values)\n",
    "y_balanced = balanced_df['y'].values\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y_balanced)\n",
    "y_cat = to_categorical(y_encoded)\n",
    "np.save(\"classes.npy\", le.classes_)\n",
    "\n",
    "# ==== Train-Validation Split ====\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_balanced, y_cat, test_size=0.2, stratify=y_cat, random_state=42)\n",
    "\n",
    "# ==== Model Definition ====\n",
    "model = Sequential([\n",
    "    Conv1D(64, 5, activation='relu', padding='same', input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling1D(2),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Conv1D(128, 3, activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling1D(2),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Conv1D(256, 3, activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling1D(2),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.4),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(y_cat.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# ==== Callbacks ====\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', patience=4, factor=0.5, verbose=1)\n",
    "]\n",
    "\n",
    "# ==== Training ====\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val),\n",
    "                    epochs=100, batch_size=32, callbacks=callbacks)\n",
    "\n",
    "# ==== Save Model ====\n",
    "model.save(\"trained_model.h5\")\n",
    "\n",
    "# ==== Evaluation ====\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03d5bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for i, emotion in enumerate(le.classes_):\n",
    "    idx = y_true_labels == i\n",
    "    acc = accuracy_score(y_true_labels[idx], y_pred_labels[idx])\n",
    "    if acc < 0.75:\n",
    "        print(f\"❌ {emotion}: {acc:.2%} (needs improvement)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f997d254",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Get true and predicted emotion class labels\n",
    "y_true = np.argmax(y_val, axis=1)\n",
    "y_pred = np.argmax(model.predict(X_val), axis=1)\n",
    "\n",
    "# Emotion-wise accuracy\n",
    "print(\"\\n🎯 Emotion-wise Accuracy:\")\n",
    "for i, emotion in enumerate(le.classes_):\n",
    "    indices = (y_true == i)\n",
    "    class_acc = accuracy_score(y_true[indices], y_pred[indices])\n",
    "    print(f\"{emotion}: {class_acc:.2%} accuracy\")\n",
    "\n",
    "# Overall metrics\n",
    "overall_acc = accuracy_score(y_true, y_pred)\n",
    "macro_f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "print(f\"\\n✅ Overall Accuracy: {overall_acc:.2%}\")\n",
    "print(f\"✅ Macro F1 Score: {macro_f1:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e97a85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# Get predicted labels\n",
    "y_pred_labels = np.argmax(model.predict(X_val), axis=1)\n",
    "y_true_labels = np.argmax(y_val, axis=1)\n",
    "\n",
    "# Print emotion-wise accuracy\n",
    "print(\"\\n🎯 Emotion-wise Accuracy:\")\n",
    "for i, emotion in enumerate(le.classes_):\n",
    "    idx = y_true_labels == i\n",
    "    acc = accuracy_score(y_true_labels[idx], y_pred_labels[idx])\n",
    "    print(f\"{emotion}: {acc:.2%} accuracy\")\n",
    "\n",
    "# Final Metrics\n",
    "overall_acc = accuracy_score(y_true_labels, y_pred_labels)\n",
    "macro_f1 = f1_score(y_true_labels, y_pred_labels, average='macro')\n",
    "\n",
    "print(f\"\\n✅ Overall Accuracy: {overall_acc:.2%}\")\n",
    "print(f\"✅ Macro F1 Score: {macro_f1:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f481de05",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary\n",
    "model = load_model(\"trained_model.h5\")\n",
    "y_pred = model.predict(X_val)\n",
    "y_val_labels = np.argmax(y_val, axis=1)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(\"\\n✅ Classification Report:\")\n",
    "print(classification_report(y_val_labels, y_pred_labels, target_names=le.classes_))\n",
    "\n",
    "cm = confusion_matrix(y_val_labels, y_pred_labels)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98c3b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "from sklearn.utils import resample, compute_class_weight\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# ==== Configuration ====\n",
    "DATA_DIRS = [\"Audio_Song_Actors_01-24\", \"Audio_Speech_Actors_01-24\"]\n",
    "SAMPLE_RATE = 22050\n",
    "N_MFCC = 40\n",
    "MAX_LEN = 216\n",
    "\n",
    "# ==== Feature Extraction ====\n",
    "def extract_features(file_path):\n",
    "    y, sr = librosa.load(file_path, sr=SAMPLE_RATE)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=N_MFCC).T\n",
    "    chroma = librosa.feature.chroma_stft(y=y, sr=sr).T\n",
    "    zcr = librosa.feature.zero_crossing_rate(y).T\n",
    "    rms_feature = librosa.feature.rms(y=y).T\n",
    "\n",
    "    def pad(x):\n",
    "        return x[:MAX_LEN] if x.shape[0] >= MAX_LEN else np.pad(x, ((0, MAX_LEN - x.shape[0]), (0, 0)), mode='constant')\n",
    "\n",
    "    mfcc = pad(mfcc)\n",
    "    chroma = pad(chroma)\n",
    "    zcr = pad(zcr)\n",
    "    rms_feature = pad(rms_feature)\n",
    "\n",
    "    return np.concatenate([mfcc, chroma, zcr, rms_feature], axis=1)\n",
    "\n",
    "X, y = [], []\n",
    "\n",
    "# ==== Dataset Preparation ====\n",
    "for data_dir in DATA_DIRS:\n",
    "    for emotion_label in os.listdir(data_dir):\n",
    "        subfolder_path = os.path.join(data_dir, emotion_label)\n",
    "        if not os.path.isdir(subfolder_path):\n",
    "            continue\n",
    "        for file in os.listdir(subfolder_path):\n",
    "            if file.endswith(\".wav\"):\n",
    "                try:\n",
    "                    path = os.path.join(subfolder_path, file)\n",
    "                    features = extract_features(path)\n",
    "                    X.append(features)\n",
    "                    y.append(emotion_label)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {file}: {e}\")\n",
    "\n",
    "X = np.array(X)\n",
    "\n",
    "# ==== Upsample to Balance Classes ====\n",
    "df = pd.DataFrame({'x': X.tolist(), 'y': y})\n",
    "grouped = df.groupby('y')\n",
    "max_count = grouped.size().max()\n",
    "upsampled_df = grouped.apply(lambda g: g.sample(max_count, replace=True, random_state=42)).reset_index(drop=True)\n",
    "\n",
    "X_balanced = np.stack(upsampled_df['x'].values)\n",
    "y_balanced = upsampled_df['y'].values\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y_balanced)\n",
    "y_cat = to_categorical(y_encoded)\n",
    "np.save(\"classes.npy\", le.classes_)\n",
    "\n",
    "# ==== Train-Validation Split ====\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_balanced, y_cat, test_size=0.2, stratify=y_cat, random_state=42)\n",
    "\n",
    "# ==== Compute Class Weights ====\n",
    "y_int = np.argmax(y_train, axis=1)\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_int), y=y_int)\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "# ==== Model Definition ====\n",
    "model = Sequential([\n",
    "    Conv1D(64, 5, activation='relu', padding='same', input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling1D(2),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Conv1D(128, 3, activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling1D(2),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Conv1D(256, 3, activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling1D(2),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.4),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(y_cat.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# ==== Callbacks ====\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', patience=4, factor=0.5, verbose=1)\n",
    "]\n",
    "\n",
    "# ==== Training ====\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val),\n",
    "                    epochs=100, batch_size=32, callbacks=callbacks, class_weight=class_weights)\n",
    "\n",
    "# ==== Save Model ====\n",
    "model.save(\"trained_model.keras\")\n",
    "\n",
    "# ==== Evaluation ====\n",
    "y_pred = model.predict(X_val)\n",
    "y_val_labels = np.argmax(y_val, axis=1)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(\"\\n✅ Classification Report:\")\n",
    "print(classification_report(y_val_labels, y_pred_labels, target_names=le.classes_))\n",
    "\n",
    "# Emotion-wise accuracy\n",
    "print(\"\\n🎯 Emotion-wise Accuracy:\")\n",
    "for i, emotion in enumerate(le.classes_):\n",
    "    idx = y_val_labels == i\n",
    "    acc = accuracy_score(y_val_labels[idx], y_pred_labels[idx])\n",
    "    status = \"✅\" if acc >= 0.75 else \"❌\"\n",
    "    print(f\"{status} {emotion}: {acc:.2%} accuracy\")\n",
    "\n",
    "# Overall metrics\n",
    "overall_acc = accuracy_score(y_val_labels, y_pred_labels)\n",
    "macro_f1 = f1_score(y_val_labels, y_pred_labels, average='macro')\n",
    "print(f\"\\n✅ Overall Accuracy: {overall_acc:.2%}\")\n",
    "print(f\"✅ Macro F1 Score: {macro_f1:.2%}\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_val_labels, y_pred_labels)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ==== Optional: Predict New File ====\n",
    "def predict_emotion(filepath):\n",
    "    model = load_model(\"trained_model.h5\")\n",
    "    classes = np.load(\"classes.npy\")\n",
    "    features = extract_features(filepath)\n",
    "    features = np.expand_dims(features, axis=0)\n",
    "    pred = model.predict(features)\n",
    "    return classes[np.argmax(pred)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6429fd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# Get predicted labels\n",
    "y_pred_labels = np.argmax(model.predict(X_val), axis=1)\n",
    "y_true_labels = np.argmax(y_val, axis=1)\n",
    "\n",
    "# Print emotion-wise accuracy\n",
    "print(\"\\n🎯 Emotion-wise Accuracy:\")\n",
    "for i, emotion in enumerate(le.classes_):\n",
    "    idx = y_true_labels == i\n",
    "    acc = accuracy_score(y_true_labels[idx], y_pred_labels[idx])\n",
    "    print(f\"{emotion}: {acc:.2%} accuracy\")\n",
    "\n",
    "# Final Metrics\n",
    "overall_acc = accuracy_score(y_true_labels, y_pred_labels)\n",
    "macro_f1 = f1_score(y_true_labels, y_pred_labels, average='macro')\n",
    "\n",
    "print(f\"\\n✅ Overall Accuracy: {overall_acc:.2%}\")\n",
    "print(f\"✅ Macro F1 Score: {macro_f1:.2%}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
